{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretability & Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/modelingData/modelingDataFrame.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabNet - Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_names = ['Astronomical Low Tide', 'Extreme Cold/Wind Chill', 'Flood','Winter Weather', \n",
    "               'Wildfire', 'Heavy Rain', 'Cold/Wind Chill', 'Dense Fog', 'Frost/Freeze', 'Strong Wind',\n",
    "               'Lake-Effect Snow', 'Funnel Cloud', 'Flash Flood', 'Heavy Snow', 'Ice Storm', \n",
    "               'Thunderstorm Wind', 'Avalanche', 'Excessive Heat', 'Coastal Flood', 'Storm Surge/Tide', \n",
    "               'Sleet', 'Debris Flow', 'Winter Storm', 'Tropical Storm', 'Dust Storm', 'Drought', \n",
    "               'Blizzard', 'Lightning', 'Tornado', 'Hail', 'Rip Current', 'Heat', 'Freezing Fog', \n",
    "               'High Surf', 'High Wind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['ValidDataFlag'] == 1]\n",
    "df = df[~df['Year'].isin([2015, 2016, 2017])]\n",
    "\n",
    "zero_percentages = {}\n",
    "\n",
    "for col in event_names:\n",
    "    if col in df.columns:\n",
    "        zero_count = (df[col] == 0).sum()\n",
    "        total_count = len(df)\n",
    "        zero_percentage = (zero_count / total_count) * 100\n",
    "        zero_percentages[col] = zero_percentage\n",
    "\n",
    "zero_percentages_df = pd.DataFrame.from_dict(zero_percentages, orient='index', columns=['%_zero'])\n",
    "zero_percentages_df = zero_percentages_df.sort_values('%_zero', ascending=False)\n",
    "\n",
    "selected_events_name = [\n",
    "    col for col, perc in zero_percentages.items() if perc < 99.8\n",
    "]\n",
    "\n",
    "target = 'CustomersOut'\n",
    "\n",
    "numeric_features = ['Tmin', 'Tmax', 'Tavg', 'Ppt', 'Lat', 'Lng']\n",
    "categorical_features = ['Season', 'Region', 'Division', 'Month', 'StateName', 'CountyName']\n",
    "event_features = [col for col in df.columns if col in selected_events_name]\n",
    "\n",
    "X = df[numeric_features + categorical_features + event_features]\n",
    "y = df[target]\n",
    "\n",
    "X_encoded = X.copy()\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    X_encoded[col] = le.fit_transform(X_encoded[col].astype(str))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# później podmień na lepszy model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\olenk\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "model_loaded = TabNetRegressor()\n",
    "model_loaded.load_model('../models/tabnet_model.zip')\n",
    "preds = model_loaded.predict(X_test.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_matrix, masks = model_loaded.explain(X_test.values)\n",
    "feature_importance = np.mean(masks[0], axis=0)\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': X_test.columns,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "display(feature_importance_df[feature_importance_df['importance'] > 0.001])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
