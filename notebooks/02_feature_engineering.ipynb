{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering & Justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\olenk\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from data_preprocessing import * \n",
    "from feature_engineering import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stormEvents_2014 = pd.read_csv(\"../data/NOAA_StormEvents/StormEvents_details-ftp_v1.0_d2014_c20231116.csv\")\n",
    "stormEvents_2015 = pd.read_csv(\"../data/NOAA_StormEvents/StormEvents_details-ftp_v1.0_d2015_c20240716.csv\")\n",
    "stormEvents_2016 = pd.read_csv(\"../data/NOAA_StormEvents/StormEvents_details-ftp_v1.0_d2016_c20220719.csv\")\n",
    "stormEvents_2017 = pd.read_csv(\"../data/NOAA_StormEvents/StormEvents_details-ftp_v1.0_d2017_c20230317.csv\")\n",
    "stormEvents_2018 = pd.read_csv(\"../data/NOAA_StormEvents/StormEvents_details-ftp_v1.0_d2018_c20240716.csv\")\n",
    "stormEvents_2019 = pd.read_csv(\"../data/NOAA_StormEvents/StormEvents_details-ftp_v1.0_d2019_c20240117.csv\")\n",
    "stormEvents_2020 = pd.read_csv(\"../data/NOAA_StormEvents/StormEvents_details-ftp_v1.0_d2020_c20240620.csv\")\n",
    "stormEvents_2021 = pd.read_csv(\"../data/NOAA_StormEvents/StormEvents_details-ftp_v1.0_d2021_c20240716.csv\")\n",
    "stormEvents_2022 = pd.read_csv(\"../data/NOAA_StormEvents/StormEvents_details-ftp_v1.0_d2022_c20241121.csv\")\n",
    "stormEvents_2023 = pd.read_csv(\"../data/NOAA_StormEvents/StormEvents_details-ftp_v1.0_d2023_c20241216.csv\")\n",
    "\n",
    "stormEvents_dfs = [stormEvents_2014, stormEvents_2015, stormEvents_2016, stormEvents_2017, stormEvents_2018,\n",
    "       stormEvents_2019, stormEvents_2020, stormEvents_2021, stormEvents_2022, stormEvents_2023]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "eaglei_outages_2014 = pd.read_csv(\"../data/eaglei_data/eaglei_outages_2014.csv\")\n",
    "eaglei_outages_2015 = pd.read_csv(\"../data/eaglei_data/eaglei_outages_2015.csv\")\n",
    "eaglei_outages_2016 = pd.read_csv(\"../data/eaglei_data/eaglei_outages_2016.csv\")\n",
    "eaglei_outages_2017 = pd.read_csv(\"../data/eaglei_data/eaglei_outages_2017.csv\")\n",
    "eaglei_outages_2018 = pd.read_csv(\"../data/eaglei_data/eaglei_outages_2018.csv\")\n",
    "eaglei_outages_2019 = pd.read_csv(\"../data/eaglei_data/eaglei_outages_2019.csv\")\n",
    "eaglei_outages_2020 = pd.read_csv(\"../data/eaglei_data/eaglei_outages_2020.csv\")\n",
    "eaglei_outages_2021 = pd.read_csv(\"../data/eaglei_data/eaglei_outages_2021.csv\")\n",
    "eaglei_outages_2022 = pd.read_csv(\"../data/eaglei_data/eaglei_outages_2022.csv\")\n",
    "eaglei_outages_2023 = pd.read_csv(\"../data/eaglei_data/eaglei_outages_2023.csv\")\n",
    "\n",
    "\n",
    "outages_dfs = [eaglei_outages_2014, eaglei_outages_2015, eaglei_outages_2016, eaglei_outages_2017, eaglei_outages_2018,\n",
    "               eaglei_outages_2019, eaglei_outages_2020, eaglei_outages_2021, eaglei_outages_2022, eaglei_outages_2023]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = load_data('../data/weather_data/weather_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOAA_StormEvents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_overall_missing(dfs, names=None):\n",
    "    summaries = []\n",
    "    \n",
    "    for i, df in enumerate(dfs):\n",
    "        dataset_name = names[i] if names else f\"stormEvents_{2014+i}\"\n",
    "        \n",
    "        missing_count = df['MAGNITUDE'].isna().sum()\n",
    "        present_count = df['MAGNITUDE'].notna().sum()\n",
    "        total_count = len(df)\n",
    "        \n",
    "        summaries.append({\n",
    "            'DATASET': dataset_name,\n",
    "            'MISSING_MAGNITUDE': missing_count,\n",
    "            'PRESENT_MAGNITUDE': present_count,\n",
    "            'MISSING_PERCENT': round((missing_count / total_count) * 100, 2)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATASET</th>\n",
       "      <th>MISSING_MAGNITUDE</th>\n",
       "      <th>PRESENT_MAGNITUDE</th>\n",
       "      <th>MISSING_PERCENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stormEvents_2014</td>\n",
       "      <td>29969</td>\n",
       "      <td>29506</td>\n",
       "      <td>50.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stormEvents_2015</td>\n",
       "      <td>29273</td>\n",
       "      <td>28634</td>\n",
       "      <td>50.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stormEvents_2016</td>\n",
       "      <td>24661</td>\n",
       "      <td>31344</td>\n",
       "      <td>44.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stormEvents_2017</td>\n",
       "      <td>23330</td>\n",
       "      <td>33699</td>\n",
       "      <td>40.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stormEvents_2018</td>\n",
       "      <td>34063</td>\n",
       "      <td>28634</td>\n",
       "      <td>54.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>stormEvents_2019</td>\n",
       "      <td>32244</td>\n",
       "      <td>35617</td>\n",
       "      <td>47.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>stormEvents_2020</td>\n",
       "      <td>26418</td>\n",
       "      <td>34861</td>\n",
       "      <td>43.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>stormEvents_2021</td>\n",
       "      <td>31333</td>\n",
       "      <td>30056</td>\n",
       "      <td>51.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>stormEvents_2022</td>\n",
       "      <td>36148</td>\n",
       "      <td>33738</td>\n",
       "      <td>51.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>stormEvents_2023</td>\n",
       "      <td>35327</td>\n",
       "      <td>40269</td>\n",
       "      <td>46.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            DATASET  MISSING_MAGNITUDE  PRESENT_MAGNITUDE  MISSING_PERCENT\n",
       "0  stormEvents_2014              29969              29506            50.39\n",
       "1  stormEvents_2015              29273              28634            50.55\n",
       "2  stormEvents_2016              24661              31344            44.03\n",
       "3  stormEvents_2017              23330              33699            40.91\n",
       "4  stormEvents_2018              34063              28634            54.33\n",
       "5  stormEvents_2019              32244              35617            47.51\n",
       "6  stormEvents_2020              26418              34861            43.11\n",
       "7  stormEvents_2021              31333              30056            51.04\n",
       "8  stormEvents_2022              36148              33738            51.72\n",
       "9  stormEvents_2023              35327              40269            46.73"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_overall_missing(stormEvents_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important columns in the Storm Events dataset is **MAGNITUDE**, which allows us to assess the intensity of events. Unfortunately, for most events, this column is empty, with around 50% of the data missing in each dataset and around 60% of missing data in **MAGNITUDE_TYPE**. As a result, we will not be able to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eaglei_Outages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POMYSŁ: może dołożymy procent ludzi bez prądu, w ten sposób będziemy miały miarę mówiącą o natężeniu braku dostawy. jakiego procenta ludzi możemy się spodziewać bez dostępu (to też w kontekście ułożenia historyjki będzie dobre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dobra byłoby miło gdyby nie fakt, że czasmia(a nawet często wyskakuje więcej niz 100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max percent_out: 137300.0\n",
      "Min percent_out: 2.6577366714505926e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips_code</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>customers_out</th>\n",
       "      <th>run_start_time</th>\n",
       "      <th>Customers</th>\n",
       "      <th>percent_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148931</th>\n",
       "      <td>37095</td>\n",
       "      <td>Hyde</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>2608.0</td>\n",
       "      <td>2020-01-03 05:45:00</td>\n",
       "      <td>700.0</td>\n",
       "      <td>372.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149540</th>\n",
       "      <td>37095</td>\n",
       "      <td>Hyde</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>2608.0</td>\n",
       "      <td>2020-01-03 06:00:00</td>\n",
       "      <td>700.0</td>\n",
       "      <td>372.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150146</th>\n",
       "      <td>37095</td>\n",
       "      <td>Hyde</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>2608.0</td>\n",
       "      <td>2020-01-03 06:15:00</td>\n",
       "      <td>700.0</td>\n",
       "      <td>372.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150766</th>\n",
       "      <td>37095</td>\n",
       "      <td>Hyde</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>2608.0</td>\n",
       "      <td>2020-01-03 06:30:00</td>\n",
       "      <td>700.0</td>\n",
       "      <td>372.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151383</th>\n",
       "      <td>37095</td>\n",
       "      <td>Hyde</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>2608.0</td>\n",
       "      <td>2020-01-03 06:45:00</td>\n",
       "      <td>700.0</td>\n",
       "      <td>372.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25536588</th>\n",
       "      <td>37089</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2020-12-30 20:45:00</td>\n",
       "      <td>24.0</td>\n",
       "      <td>179.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25537339</th>\n",
       "      <td>37089</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2020-12-30 21:00:00</td>\n",
       "      <td>24.0</td>\n",
       "      <td>179.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25538083</th>\n",
       "      <td>37089</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2020-12-30 21:15:00</td>\n",
       "      <td>24.0</td>\n",
       "      <td>179.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25538823</th>\n",
       "      <td>37089</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2020-12-30 21:30:00</td>\n",
       "      <td>24.0</td>\n",
       "      <td>179.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25539543</th>\n",
       "      <td>37089</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2020-12-30 21:45:00</td>\n",
       "      <td>24.0</td>\n",
       "      <td>179.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20532 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fips_code     county           state  customers_out  \\\n",
       "148931       37095       Hyde  North Carolina         2608.0   \n",
       "149540       37095       Hyde  North Carolina         2608.0   \n",
       "150146       37095       Hyde  North Carolina         2608.0   \n",
       "150766       37095       Hyde  North Carolina         2608.0   \n",
       "151383       37095       Hyde  North Carolina         2608.0   \n",
       "...            ...        ...             ...            ...   \n",
       "25536588     37089  Henderson  North Carolina           43.0   \n",
       "25537339     37089  Henderson  North Carolina           43.0   \n",
       "25538083     37089  Henderson  North Carolina           43.0   \n",
       "25538823     37089  Henderson  North Carolina           43.0   \n",
       "25539543     37089  Henderson  North Carolina           43.0   \n",
       "\n",
       "               run_start_time  Customers  percent_out  \n",
       "148931    2020-01-03 05:45:00      700.0   372.571429  \n",
       "149540    2020-01-03 06:00:00      700.0   372.571429  \n",
       "150146    2020-01-03 06:15:00      700.0   372.571429  \n",
       "150766    2020-01-03 06:30:00      700.0   372.571429  \n",
       "151383    2020-01-03 06:45:00      700.0   372.571429  \n",
       "...                       ...        ...          ...  \n",
       "25536588  2020-12-30 20:45:00       24.0   179.166667  \n",
       "25537339  2020-12-30 21:00:00       24.0   179.166667  \n",
       "25538083  2020-12-30 21:15:00       24.0   179.166667  \n",
       "25538823  2020-12-30 21:30:00       24.0   179.166667  \n",
       "25539543  2020-12-30 21:45:00       24.0   179.166667  \n",
       "\n",
       "[20532 rows x 7 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcc = pd.read_csv(\"../data/eaglei_data/MCC.csv\")\n",
    "mcc[\"County_FIPS\"] = mcc[\"County_FIPS\"].astype(str)\n",
    "dfs = [eaglei_outages_2020]\n",
    "\n",
    "for i, df in enumerate(dfs):\n",
    "    df[\"fips_code\"] = df[\"fips_code\"].astype(str)  \n",
    "    df = df.merge(mcc, left_on=\"fips_code\", right_on=\"County_FIPS\", how=\"left\") \n",
    "    df[\"percent_out\"] = (df[\"customers_out\"] / df[\"Customers\"]) * 100\n",
    "    dfs[i] = df.drop(columns=[\"County_FIPS\"])\n",
    "\n",
    "\n",
    "\n",
    "max_value = dfs[0][\"percent_out\"].max()\n",
    "min_value = dfs[0][\"percent_out\"].min()\n",
    "\n",
    "print(f\"Max percent_out: {max_value}\")\n",
    "print(f\"Min percent_out: {min_value}\")\n",
    "\n",
    "dfs[0][dfs[0][\"percent_out\"] > 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values in the latitude and longitude columns will be filled using the geopy library, which can convert a place (like a county) into its corresponding latitude and longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nom = ArcGIS()\n",
    "def get_coordinates(county_name):\n",
    "    try:\n",
    "        location = nom.geocode(county_name)\n",
    "        if location:\n",
    "            return location.latitude, location.longitude\n",
    "    except (GeocoderTimedOut, GeocoderServiceError) as e:\n",
    "        print(f\"Error geocoding {county_name}: {e}\")\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in stormEvents_2014.iterrows():\n",
    "    if pd.isna(row['BEGIN_LAT']) or pd.isna(row['BEGIN_LON']):\n",
    "        lat, lon = get_coordinates(row['CZ_NAME'])\n",
    "        if lat is not None and lon is not None:\n",
    "            stormEvents_2014.at[index, 'BEGIN_LAT'] = lat\n",
    "            stormEvents_2014.at[index, 'BEGIN_LON'] = lon\n",
    "            stormEvents_2014.at[index, 'END_LAT'] = lat\n",
    "            stormEvents_2014.at[index, 'END_LON'] = lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stormEvents_2014[['CZ_NAME', 'BEGIN_LAT', 'BEGIN_LON']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
